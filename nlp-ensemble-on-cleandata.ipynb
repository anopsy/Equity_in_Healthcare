{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":65862,"databundleVersionId":7469115,"sourceType":"competition"},{"sourceId":7670440,"sourceType":"datasetVersion","datasetId":4450702}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2024-02-22T08:18:43.325097Z","iopub.execute_input":"2024-02-22T08:18:43.325540Z","iopub.status.idle":"2024-02-22T08:18:44.545593Z","shell.execute_reply.started":"2024-02-22T08:18:43.325505Z","shell.execute_reply":"2024-02-22T08:18:44.543956Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/equity-in-healthcare-clean-datasets/train_clean.csv\n/kaggle/input/equity-in-healthcare-clean-datasets/test_clean.csv\n/kaggle/input/widsdatathon2024-challenge1/sample_submission.csv\n/kaggle/input/widsdatathon2024-challenge1/training.csv\n/kaggle/input/widsdatathon2024-challenge1/test.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# This notebook makes use of the clean and wrangled version of the original dataset. You can find the data sets here:\nhttps://www.kaggle.com/datasets/anopsy/equity-in-healthcare-clean-datasets","metadata":{}},{"cell_type":"markdown","source":"# If you like the notebook don't hestitate to give it a thumb up. ALso any suggestions on how to handle tokenization in a better and more informative way or how to perform Stacking Ensemble are welcome! Happy coding!","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/equity-in-healthcare-clean-datasets/train_clean.csv')\ntest = pd.read_csv('/kaggle/input/equity-in-healthcare-clean-datasets/test_clean.csv')","metadata":{"execution":{"iopub.status.busy":"2024-02-21T10:59:42.973928Z","iopub.execute_input":"2024-02-21T10:59:42.974346Z","iopub.status.idle":"2024-02-21T10:59:43.647525Z","shell.execute_reply.started":"2024-02-21T10:59:42.974311Z","shell.execute_reply":"2024-02-21T10:59:43.646351Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"for col in train.columns:\n    print(col)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T11:00:03.498650Z","iopub.execute_input":"2024-02-21T11:00:03.499073Z","iopub.status.idle":"2024-02-21T11:00:03.508110Z","shell.execute_reply.started":"2024-02-21T11:00:03.499041Z","shell.execute_reply":"2024-02-21T11:00:03.506458Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"index\npatient_id\npatient_state\npatient_zip3\npatient_age\nbreast_cancer_diagnosis_code\nbreast_cancer_diagnosis_desc\nmetastatic_cancer_diagnosis_code\nRegion\nDivision\npopulation\ndensity\nage_median\nage_under_10\nage_10_to_19\nage_20s\nage_30s\nage_40s\nage_50s\nage_60s\nage_70s\nage_over_80\nmale\nfemale\nmarried\ndivorced\nnever_married\nwidowed\nfamily_size\nfamily_dual_income\nincome_household_median\nincome_household_under_5\nincome_household_5_to_10\nincome_household_10_to_15\nincome_household_15_to_20\nincome_household_20_to_25\nincome_household_25_to_35\nincome_household_35_to_50\nincome_household_50_to_75\nincome_household_75_to_100\nincome_household_100_to_150\nincome_household_150_over\nincome_household_six_figure\nincome_individual_median\nhome_ownership\nhousing_units\nhome_value\nrent_median\nrent_burden\neducation_less_highschool\neducation_highschool\neducation_some_college\neducation_bachelors\neducation_graduate\neducation_college_or_above\neducation_stem_degree\nlabor_force_participation\nunemployment_rate\nself_employed\nfarmer\nrace_white\nrace_black\nrace_asian\nrace_native\nrace_pacific\nrace_other\nrace_multiple\nhispanic\ndisabled\npoverty\nlimited_english\ncommute_time\nhealth_uninsured\nveteran\nOzone\nPM25\nN02\npayer_type\npatient_race\nbmi\nunderweight\nobese\nyoung_ind\ndesolated\nhome_wealth\nair_quality\nwealth_index\neducation_ratio\nhh_income_ratio\nage_ratio\nrace_ration\nDiagPeriodL90D\n","output_type":"stream"}]},{"cell_type":"code","source":"train.drop(columns = ['female', 'male'], inplace= True)\ntest.drop(columns = ['female', 'male'], inplace= True)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T11:01:11.068316Z","iopub.execute_input":"2024-02-21T11:01:11.068936Z","iopub.status.idle":"2024-02-21T11:01:11.092348Z","shell.execute_reply.started":"2024-02-21T11:01:11.068884Z","shell.execute_reply":"2024-02-21T11:01:11.091078Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Let's combine the dataframes to further work on the features","metadata":{}},{"cell_type":"code","source":"whole_df = pd.concat([train.drop(columns=['DiagPeriodL90D']), test])","metadata":{"execution":{"iopub.status.busy":"2024-02-21T11:01:12.550509Z","iopub.execute_input":"2024-02-21T11:01:12.550924Z","iopub.status.idle":"2024-02-21T11:01:12.575672Z","shell.execute_reply.started":"2024-02-21T11:01:12.550892Z","shell.execute_reply":"2024-02-21T11:01:12.574561Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# I'll start with tokenizing the 'breast_cancer_diagnosis_desc' column. I'll will use nltk and TfidVectorizer. That's my first iteration, so I 'll keep it simple, but I'm consdiering using n-grams later on","metadata":{}},{"cell_type":"code","source":"from nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport nltk\n","metadata":{"execution":{"iopub.status.busy":"2024-02-21T11:01:13.444597Z","iopub.execute_input":"2024-02-21T11:01:13.445095Z","iopub.status.idle":"2024-02-21T11:01:14.996913Z","shell.execute_reply.started":"2024-02-21T11:01:13.445056Z","shell.execute_reply":"2024-02-21T11:01:14.995784Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# I'm replacing some of the shorter words and can proceed with toneizing and changing the tokens into vectors","metadata":{}},{"cell_type":"code","source":"nltk.download('stopwords')\n\nstop_words = set(stopwords.words('english'))\nwhole_df['processed_description'] = whole_df['breast_cancer_diagnosis_desc'].apply(lambda x: ' '.join(word for word in x.lower().split() if word not in stop_words))\n\n\nmapping_dict = {\n    'malig': 'malignant',\n    'unsp': 'unspecified',\n    'ovrlp': 'overlapping',\n    'neoplm' : 'neoplasm',\n    \n}\n\n\ndef replace_words(text):\n    return ' '.join(mapping_dict.get(word, word) for word in text.split())\n\n\nwhole_df['processed_description'] = whole_df['processed_description'].apply(replace_words)\nwhole_df['tokenized_description'] = whole_df['processed_description'].apply(nltk.word_tokenize)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T11:01:14.998462Z","iopub.execute_input":"2024-02-21T11:01:14.998783Z","iopub.status.idle":"2024-02-21T11:01:19.131690Z","shell.execute_reply.started":"2024-02-21T11:01:14.998756Z","shell.execute_reply":"2024-02-21T11:01:19.129902Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"whole_df['tokenized_description']","metadata":{"execution":{"iopub.status.busy":"2024-02-21T11:01:19.134187Z","iopub.execute_input":"2024-02-21T11:01:19.134662Z","iopub.status.idle":"2024-02-21T11:01:19.151873Z","shell.execute_reply.started":"2024-02-21T11:01:19.134621Z","shell.execute_reply":"2024-02-21T11:01:19.149834Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"0       [malignant, neoplasm, unspecified, site, unspe...\n1       [malignant, neoplasm, upper-outer, quadrant, r...\n2       [malignant, neoplasm, central, portion, left, ...\n3       [malignant, neoplasm, upper-inner, quadrant, l...\n4       [malignant, neoplasm, breast, (, female, ), ,,...\n                              ...                        \n5787    [malignant, neoplasm, upper-outer, quadrant, r...\n5788    [malignant, neoplasm, unspecified, site, left,...\n5789    [malignant, neoplasm, upper-outer, quadrant, r...\n5790    [malignant, neoplasm, breast, (, female, ), ,,...\n5791    [malignant, neoplasm, central, portion, right,...\nName: tokenized_description, Length: 18698, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"whole_df['tokenized_description'] = whole_df['tokenized_description'].str.join(' ')\n\n\ntfidf = TfidfVectorizer()\ntfidf_matrix = tfidf.fit_transform(whole_df['tokenized_description'])\ntfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())","metadata":{"execution":{"iopub.status.busy":"2024-02-21T11:01:19.154092Z","iopub.execute_input":"2024-02-21T11:01:19.154553Z","iopub.status.idle":"2024-02-21T11:01:19.455276Z","shell.execute_reply.started":"2024-02-21T11:01:19.154519Z","shell.execute_reply":"2024-02-21T11:01:19.453809Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Now I can look at my dataframe with tokens and combine it with the other features.","metadata":{}},{"cell_type":"code","source":"tfidf_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-21T11:01:19.457959Z","iopub.execute_input":"2024-02-21T11:01:19.458326Z","iopub.status.idle":"2024-02-21T11:01:19.495640Z","shell.execute_reply.started":"2024-02-21T11:01:19.458297Z","shell.execute_reply":"2024-02-21T11:01:19.494541Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"   areola  axillary    breast   central    female     inner      left  lower  \\\n0     0.0       0.0  0.236507  0.000000  0.236913  0.000000  0.000000    0.0   \n1     0.0       0.0  0.196357  0.000000  0.196693  0.000000  0.000000    0.0   \n2     0.0       0.0  0.150693  0.633317  0.150952  0.000000  0.326976    0.0   \n3     0.0       0.0  0.176346  0.000000  0.176648  0.622059  0.382636    0.0   \n4     0.0       0.0  0.391461  0.000000  0.392131  0.000000  0.000000    0.0   \n\n   male  malignant  ...   portion  quadrant     right  secondary     site  \\\n0   0.0   0.236495  ...  0.000000  0.000000  0.000000        0.0  0.46011   \n1   0.0   0.196346  ...  0.000000  0.436085  0.416451        0.0  0.00000   \n2   0.0   0.150685  ...  0.633317  0.000000  0.000000        0.0  0.00000   \n3   0.0   0.176336  ...  0.000000  0.391643  0.000000        0.0  0.00000   \n4   0.0   0.391440  ...  0.000000  0.000000  0.000000        0.0  0.00000   \n\n   sites  specified  tail  unspecified     upper  \n0    0.0        0.0   0.0     0.751250  0.000000  \n1    0.0        0.0   0.0     0.000000  0.483763  \n2    0.0        0.0   0.0     0.000000  0.000000  \n3    0.0        0.0   0.0     0.000000  0.434462  \n4    0.0        0.0   0.0     0.621724  0.000000  \n\n[5 rows x 24 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>areola</th>\n      <th>axillary</th>\n      <th>breast</th>\n      <th>central</th>\n      <th>female</th>\n      <th>inner</th>\n      <th>left</th>\n      <th>lower</th>\n      <th>male</th>\n      <th>malignant</th>\n      <th>...</th>\n      <th>portion</th>\n      <th>quadrant</th>\n      <th>right</th>\n      <th>secondary</th>\n      <th>site</th>\n      <th>sites</th>\n      <th>specified</th>\n      <th>tail</th>\n      <th>unspecified</th>\n      <th>upper</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.236507</td>\n      <td>0.000000</td>\n      <td>0.236913</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.236495</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.46011</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.751250</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.196357</td>\n      <td>0.000000</td>\n      <td>0.196693</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.196346</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.436085</td>\n      <td>0.416451</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.483763</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.150693</td>\n      <td>0.633317</td>\n      <td>0.150952</td>\n      <td>0.000000</td>\n      <td>0.326976</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.150685</td>\n      <td>...</td>\n      <td>0.633317</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.176346</td>\n      <td>0.000000</td>\n      <td>0.176648</td>\n      <td>0.622059</td>\n      <td>0.382636</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.176336</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.391643</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.434462</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.391461</td>\n      <td>0.000000</td>\n      <td>0.392131</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.391440</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.621724</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 24 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"whole_df.reset_index(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T11:01:23.043846Z","iopub.execute_input":"2024-02-21T11:01:23.044378Z","iopub.status.idle":"2024-02-21T11:01:23.050622Z","shell.execute_reply.started":"2024-02-21T11:01:23.044341Z","shell.execute_reply":"2024-02-21T11:01:23.049332Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"tokenized_df = pd.concat([whole_df, tfidf_df], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T11:01:23.258213Z","iopub.execute_input":"2024-02-21T11:01:23.258594Z","iopub.status.idle":"2024-02-21T11:01:23.298959Z","shell.execute_reply.started":"2024-02-21T11:01:23.258559Z","shell.execute_reply":"2024-02-21T11:01:23.297890Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# I remove the intermediate columns I created in the process","metadata":{}},{"cell_type":"code","source":"tokenized_df.drop(columns=['processed_description', 'tokenized_description'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T11:01:24.335158Z","iopub.execute_input":"2024-02-21T11:01:24.335542Z","iopub.status.idle":"2024-02-21T11:01:24.356226Z","shell.execute_reply.started":"2024-02-21T11:01:24.335513Z","shell.execute_reply":"2024-02-21T11:01:24.355059Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# It's time to get the dtypes right.","metadata":{}},{"cell_type":"code","source":"tokenized_df_types = tokenized_df.dtypes.to_dict()\n\nfor key in tokenized_df_types:\n    if tokenized_df_types[key] =='O':\n        tokenized_df[key] = tokenized_df[key].astype('category')","metadata":{"execution":{"iopub.status.busy":"2024-02-21T11:01:26.734313Z","iopub.execute_input":"2024-02-21T11:01:26.734789Z","iopub.status.idle":"2024-02-21T11:01:26.771883Z","shell.execute_reply.started":"2024-02-21T11:01:26.734753Z","shell.execute_reply":"2024-02-21T11:01:26.769889Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"tokenized_df['patient_zip3']=tokenized_df['patient_zip3'].astype('category')\ntokenized_df.dtypes","metadata":{"execution":{"iopub.status.busy":"2024-02-21T11:01:27.310378Z","iopub.execute_input":"2024-02-21T11:01:27.310809Z","iopub.status.idle":"2024-02-21T11:01:27.322017Z","shell.execute_reply.started":"2024-02-21T11:01:27.310776Z","shell.execute_reply":"2024-02-21T11:01:27.320923Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"level_0             int64\nindex               int64\npatient_id          int64\npatient_state    category\npatient_zip3     category\n                   ...   \nsites             float64\nspecified         float64\ntail              float64\nunspecified       float64\nupper             float64\nLength: 114, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"num_col = tokenized_df.select_dtypes(exclude=['category']).columns\ncat_col = tokenized_df.select_dtypes(include=['category']).columns\n","metadata":{"execution":{"iopub.status.busy":"2024-02-21T11:01:29.494994Z","iopub.execute_input":"2024-02-21T11:01:29.495388Z","iopub.status.idle":"2024-02-21T11:01:29.529113Z","shell.execute_reply.started":"2024-02-21T11:01:29.495358Z","shell.execute_reply":"2024-02-21T11:01:29.527654Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"tokenized_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-21T11:01:43.807535Z","iopub.execute_input":"2024-02-21T11:01:43.808220Z","iopub.status.idle":"2024-02-21T11:01:43.842898Z","shell.execute_reply.started":"2024-02-21T11:01:43.808182Z","shell.execute_reply":"2024-02-21T11:01:43.841907Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"   level_0  index  patient_id patient_state patient_zip3  patient_age  \\\n0        0      0      475714            CA          924           84   \n1        1      1      349367            CA          928           62   \n2        2      2      138632            TX          760           43   \n3        3      3      617843            CA          926           45   \n4        4      4      817482            ID          836           55   \n\n  breast_cancer_diagnosis_code  \\\n0                       C50919   \n1                       C50411   \n2                       C50112   \n3                       C50212   \n4                         1749   \n\n                        breast_cancer_diagnosis_desc  \\\n0  Malignant neoplasm of unsp site of unspecified...   \n1  Malig neoplm of upper-outer quadrant of right ...   \n2  Malignant neoplasm of central portion of left ...   \n3  Malig neoplasm of upper-inner quadrant of left...   \n4  Malignant neoplasm of breast (female), unspeci...   \n\n  metastatic_cancer_diagnosis_code Region  ...   portion  quadrant     right  \\\n0                            C7989   West  ...  0.000000  0.000000  0.000000   \n1                             C773   West  ...  0.000000  0.436085  0.416451   \n2                             C773  South  ...  0.633317  0.000000  0.000000   \n3                             C773   West  ...  0.000000  0.391643  0.000000   \n4                             C773   West  ...  0.000000  0.000000  0.000000   \n\n   secondary     site  sites  specified  tail  unspecified     upper  \n0        0.0  0.46011    0.0        0.0   0.0     0.751250  0.000000  \n1        0.0  0.00000    0.0        0.0   0.0     0.000000  0.483763  \n2        0.0  0.00000    0.0        0.0   0.0     0.000000  0.000000  \n3        0.0  0.00000    0.0        0.0   0.0     0.000000  0.434462  \n4        0.0  0.00000    0.0        0.0   0.0     0.621724  0.000000  \n\n[5 rows x 114 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>level_0</th>\n      <th>index</th>\n      <th>patient_id</th>\n      <th>patient_state</th>\n      <th>patient_zip3</th>\n      <th>patient_age</th>\n      <th>breast_cancer_diagnosis_code</th>\n      <th>breast_cancer_diagnosis_desc</th>\n      <th>metastatic_cancer_diagnosis_code</th>\n      <th>Region</th>\n      <th>...</th>\n      <th>portion</th>\n      <th>quadrant</th>\n      <th>right</th>\n      <th>secondary</th>\n      <th>site</th>\n      <th>sites</th>\n      <th>specified</th>\n      <th>tail</th>\n      <th>unspecified</th>\n      <th>upper</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>475714</td>\n      <td>CA</td>\n      <td>924</td>\n      <td>84</td>\n      <td>C50919</td>\n      <td>Malignant neoplasm of unsp site of unspecified...</td>\n      <td>C7989</td>\n      <td>West</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.46011</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.751250</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>349367</td>\n      <td>CA</td>\n      <td>928</td>\n      <td>62</td>\n      <td>C50411</td>\n      <td>Malig neoplm of upper-outer quadrant of right ...</td>\n      <td>C773</td>\n      <td>West</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.436085</td>\n      <td>0.416451</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.483763</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>138632</td>\n      <td>TX</td>\n      <td>760</td>\n      <td>43</td>\n      <td>C50112</td>\n      <td>Malignant neoplasm of central portion of left ...</td>\n      <td>C773</td>\n      <td>South</td>\n      <td>...</td>\n      <td>0.633317</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>617843</td>\n      <td>CA</td>\n      <td>926</td>\n      <td>45</td>\n      <td>C50212</td>\n      <td>Malig neoplasm of upper-inner quadrant of left...</td>\n      <td>C773</td>\n      <td>West</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.391643</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.434462</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>817482</td>\n      <td>ID</td>\n      <td>836</td>\n      <td>55</td>\n      <td>1749</td>\n      <td>Malignant neoplasm of breast (female), unspeci...</td>\n      <td>C773</td>\n      <td>West</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.621724</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 114 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\ntrain_new = tokenized_df[:12906]\ntest_new = tokenized_df[12906:]","metadata":{"execution":{"iopub.status.busy":"2024-02-21T11:03:09.299514Z","iopub.execute_input":"2024-02-21T11:03:09.300022Z","iopub.status.idle":"2024-02-21T11:03:09.307163Z","shell.execute_reply.started":"2024-02-21T11:03:09.299982Z","shell.execute_reply":"2024-02-21T11:03:09.305820Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"train_new['DiagPeriodL90D'] = train['DiagPeriodL90D']","metadata":{"execution":{"iopub.status.busy":"2024-02-21T11:04:06.645714Z","iopub.execute_input":"2024-02-21T11:04:06.646146Z","iopub.status.idle":"2024-02-21T11:04:06.653464Z","shell.execute_reply.started":"2024-02-21T11:04:06.646113Z","shell.execute_reply":"2024-02-21T11:04:06.652602Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/607804931.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train_new['DiagPeriodL90D'] = train['DiagPeriodL90D']\n","output_type":"stream"}]},{"cell_type":"code","source":"train_new.to_csv('train_clean.csv', index = False)\ntest_new.to_csv('test_clean.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T11:04:39.571333Z","iopub.execute_input":"2024-02-21T11:04:39.571781Z","iopub.status.idle":"2024-02-21T11:04:42.926581Z","shell.execute_reply.started":"2024-02-21T11:04:39.571728Z","shell.execute_reply":"2024-02-21T11:04:42.925251Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"print(cat_col)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T06:58:47.888634Z","iopub.execute_input":"2024-02-20T06:58:47.889173Z","iopub.status.idle":"2024-02-20T06:58:47.896825Z","shell.execute_reply.started":"2024-02-20T06:58:47.889120Z","shell.execute_reply":"2024-02-20T06:58:47.895409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in tokenized_df.columns:\n    print(col)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T06:58:47.899229Z","iopub.execute_input":"2024-02-20T06:58:47.899803Z","iopub.status.idle":"2024-02-20T06:58:47.909949Z","shell.execute_reply.started":"2024-02-20T06:58:47.899749Z","shell.execute_reply":"2024-02-20T06:58:47.908499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# I noticed in my previous notebooks, that I get better results when I strip the data frame from some of the demographic data columns. This is the selection of features I want to use in the current notebook.","metadata":{}},{"cell_type":"code","source":"num_col = ['patient_age',\n 'population',\n 'density',\n 'age_median',\n 'income_household_median',\n 'income_individual_median',\n 'home_ownership',\n 'housing_units',\n 'home_value',\n 'race_white',\n 'bmi',\n 'young_ind',\n 'desolated',\n 'home_wealth',\n 'air_quality',\n 'wealth_index',\n 'education_ratio',\n 'hh_income_ratio',\n 'age_ratio',\n 'race_ration', 'areola',\n 'axillary', 'breast','central','female','inner','left','lower','male','malignant','neoplasm','nipple',\n 'outer','overlapping','portion','quadrant','right','secondary','site','sites',\n 'specified','tail','unspecified','upper']","metadata":{"execution":{"iopub.status.busy":"2024-02-20T06:58:47.912179Z","iopub.execute_input":"2024-02-20T06:58:47.912597Z","iopub.status.idle":"2024-02-20T06:58:47.922274Z","shell.execute_reply.started":"2024-02-20T06:58:47.912560Z","shell.execute_reply":"2024-02-20T06:58:47.920882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now I can scale my data, I use for this purpose the StandardScaler since the data seems not to contain any outliers.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nfor col in num_col:\n\n    scaler.fit(tokenized_df[[col]])\n    tokenized_df[col] = scaler.transform(tokenized_df[[col]])","metadata":{"execution":{"iopub.status.busy":"2024-02-20T06:58:47.924275Z","iopub.execute_input":"2024-02-20T06:58:47.924917Z","iopub.status.idle":"2024-02-20T06:58:48.167435Z","shell.execute_reply.started":"2024-02-20T06:58:47.924859Z","shell.execute_reply":"2024-02-20T06:58:48.166113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_df[num_col]","metadata":{"execution":{"iopub.status.busy":"2024-02-20T06:58:48.169083Z","iopub.execute_input":"2024-02-20T06:58:48.169491Z","iopub.status.idle":"2024-02-20T06:58:48.227642Z","shell.execute_reply.started":"2024-02-20T06:58:48.169455Z","shell.execute_reply":"2024-02-20T06:58:48.226296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# I also create dummies for my categorical columns. I tried before Oridnal Encoder, but it seems that onehotencoding works a tiny bit better.","metadata":{}},{"cell_type":"code","source":"dummy_df = pd.concat([tokenized_df[num_col], pd.get_dummies(tokenized_df[cat_col], dtype=int)], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T06:58:48.229301Z","iopub.execute_input":"2024-02-20T06:58:48.229708Z","iopub.status.idle":"2024-02-20T06:58:48.967885Z","shell.execute_reply.started":"2024-02-20T06:58:48.229675Z","shell.execute_reply":"2024-02-20T06:58:48.965811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# After the initial runs LGBM gave mee some errors due to \"special JSON\" characters in the columns descriptions. That's why I use regex to remove them from the column names.","metadata":{}},{"cell_type":"code","source":"import re\ndummy_df = dummy_df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))","metadata":{"execution":{"iopub.status.busy":"2024-02-20T06:58:48.969551Z","iopub.execute_input":"2024-02-20T06:58:48.969935Z","iopub.status.idle":"2024-02-20T06:58:49.091550Z","shell.execute_reply.started":"2024-02-20T06:58:48.969904Z","shell.execute_reply":"2024-02-20T06:58:49.090064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# I split my dataframes back into two separate train and test df's.","metadata":{}},{"cell_type":"code","source":"train_df = dummy_df[:12906]\ntest_df = dummy_df[12906:]","metadata":{"execution":{"iopub.status.busy":"2024-02-20T06:58:49.093712Z","iopub.execute_input":"2024-02-20T06:58:49.094387Z","iopub.status.idle":"2024-02-20T06:58:49.100960Z","shell.execute_reply.started":"2024-02-20T06:58:49.094340Z","shell.execute_reply":"2024-02-20T06:58:49.099813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['DiagPeriodL90D']=train['DiagPeriodL90D'].astype('category')\ntrain_df.dtypes","metadata":{"execution":{"iopub.status.busy":"2024-02-20T06:58:49.102824Z","iopub.execute_input":"2024-02-20T06:58:49.103446Z","iopub.status.idle":"2024-02-20T06:58:49.124355Z","shell.execute_reply.started":"2024-02-20T06:58:49.103394Z","shell.execute_reply":"2024-02-20T06:58:49.121664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# I will tune hyperparameters of 4 classifiers. And then stack them. You can also find code for voting, but the results were the same. I also added Logistic Regression so the number of clf's is odd.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\nfrom sklearn.ensemble import StackingClassifier\n\nimport xgboost as xgb\nimport lightgbm as lgb\nimport catboost as cb\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.linear_model import LogisticRegression","metadata":{"execution":{"iopub.status.busy":"2024-02-20T06:58:49.127122Z","iopub.execute_input":"2024-02-20T06:58:49.128094Z","iopub.status.idle":"2024-02-20T06:58:51.757133Z","shell.execute_reply.started":"2024-02-20T06:58:49.128034Z","shell.execute_reply":"2024-02-20T06:58:51.755610Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"execution":{"iopub.status.busy":"2024-02-20T06:58:51.759440Z","iopub.execute_input":"2024-02-20T06:58:51.760048Z","iopub.status.idle":"2024-02-20T06:58:51.767315Z","shell.execute_reply.started":"2024-02-20T06:58:51.759970Z","shell.execute_reply":"2024-02-20T06:58:51.765702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le = LabelEncoder()\nX = train_df.drop(columns=['DiagPeriodL90D' ])\ny = le.fit_transform(train_df['DiagPeriodL90D'])","metadata":{"execution":{"iopub.status.busy":"2024-02-20T06:58:51.770059Z","iopub.execute_input":"2024-02-20T06:58:51.770676Z","iopub.status.idle":"2024-02-20T06:58:51.853512Z","shell.execute_reply.started":"2024-02-20T06:58:51.770619Z","shell.execute_reply":"2024-02-20T06:58:51.852130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size = 0.2, stratify=y, shuffle=True, random_state = 2137)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T06:58:51.863150Z","iopub.execute_input":"2024-02-20T06:58:51.863591Z","iopub.status.idle":"2024-02-20T06:58:51.997418Z","shell.execute_reply.started":"2024-02-20T06:58:51.863557Z","shell.execute_reply":"2024-02-20T06:58:51.996085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# This is my parameters search space. I had hard time finding out some suitable parameters ranges especially for catBoost and adaBoost. So if you have any suggestions please let  me know.","metadata":{}},{"cell_type":"code","source":"params_xgb = {\n        'min_child_weight': [1, 5, 10],\n        'gamma': [0, 0.5, 1],\n        'subsample': [0.6, 0.8],\n        'colsample_bytree': [0.6, 0.8],\n        'max_depth': [3, 4, 5],\n        'learning_rate' : [0.001, 0.01,  0.05],\n        'n_estimators' : [2000]\n        }\n\nparams_lgb = {\n        'bagging_fraction': [0.2, 0.5, 0.8],\n        'bagging_freq': [3, 5, 8],\n        'objective' :['binary'],\n        'metric': ['AUC'],\n        'feature_fraction': [0.5, 0.8],\n        'max_depth': [8, 10, 13],\n        'min_data_in_leaf': [40, 60],\n        'num_leaves': [100, 200, 500],\n        'sample_pos_weight' : [0.6],\n        'num_iterations' : [100, 200, 500]\n}\n\nparams_cat = {\n        'iterations': [100, 200, 400],\n        'learning_rate': [0.01, 0.1 , 0.5],\n        'depth': [4, 5, 6],    \n        'min_data_in_leaf' : [50, 100, 150, 200]\n    \n}\n\nparams_ada = {\n\n        'learning_rate' : [0.001, 0.01, 0.02, 0.05],\n        'n_estimators' : [20, 500, 1500]\n    \n}","metadata":{"execution":{"iopub.status.busy":"2024-02-20T09:32:22.521112Z","iopub.execute_input":"2024-02-20T09:32:22.521831Z","iopub.status.idle":"2024-02-20T09:32:22.534034Z","shell.execute_reply.started":"2024-02-20T09:32:22.521770Z","shell.execute_reply":"2024-02-20T09:32:22.533023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\nfrom sklearn.metrics import confusion_matrix, roc_auc_score","metadata":{"execution":{"iopub.status.busy":"2024-02-20T07:25:51.966308Z","iopub.execute_input":"2024-02-20T07:25:51.966783Z","iopub.status.idle":"2024-02-20T07:25:51.972063Z","shell.execute_reply.started":"2024-02-20T07:25:51.966745Z","shell.execute_reply":"2024-02-20T07:25:51.970967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits=3, shuffle = True, random_state = 2137)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T07:25:52.228397Z","iopub.execute_input":"2024-02-20T07:25:52.229087Z","iopub.status.idle":"2024-02-20T07:25:52.235402Z","shell.execute_reply.started":"2024-02-20T07:25:52.229048Z","shell.execute_reply":"2024-02-20T07:25:52.234046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tune_xgb = xgb.XGBClassifier(objective='binary:logistic', enable_categorical=True)\nrand_xgb = RandomizedSearchCV(tune_xgb, param_distributions=params_xgb, n_iter=60, scoring='roc_auc', n_jobs=4, cv=skf.split(X_train,y_train), verbose=1, random_state=2137)\nrand_xgb.fit(X_train, y_train)\nrand_xgb_pred = rand_xgb.predict_proba(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T07:25:52.455133Z","iopub.execute_input":"2024-02-20T07:25:52.456331Z","iopub.status.idle":"2024-02-20T08:48:44.644733Z","shell.execute_reply.started":"2024-02-20T07:25:52.456288Z","shell.execute_reply":"2024-02-20T08:48:44.642672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(roc_auc_score(y_test, rand_xgb_pred[:, 1]))\nprint(confusion_matrix(y_test, np.round(rand_xgb_pred[:, 1])))","metadata":{"execution":{"iopub.status.busy":"2024-02-20T08:48:44.648350Z","iopub.execute_input":"2024-02-20T08:48:44.649317Z","iopub.status.idle":"2024-02-20T08:48:44.668047Z","shell.execute_reply.started":"2024-02-20T08:48:44.649253Z","shell.execute_reply":"2024-02-20T08:48:44.666609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(rand_xgb.best_params_)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T08:48:44.669657Z","iopub.execute_input":"2024-02-20T08:48:44.670087Z","iopub.status.idle":"2024-02-20T08:48:44.676804Z","shell.execute_reply.started":"2024-02-20T08:48:44.670038Z","shell.execute_reply":"2024-02-20T08:48:44.675378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best = rand_xgb.best_estimator_\nbest_features = best.feature_importances_\nfor idx, feat in enumerate(X.columns):\n    print(feat, best_features[idx])","metadata":{"execution":{"iopub.status.busy":"2024-02-20T08:48:44.680897Z","iopub.execute_input":"2024-02-20T08:48:44.681942Z","iopub.status.idle":"2024-02-20T08:48:44.710060Z","shell.execute_reply.started":"2024-02-20T08:48:44.681886Z","shell.execute_reply":"2024-02-20T08:48:44.708818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tune_lgb = lgb.LGBMClassifier()\nrand_lgb = RandomizedSearchCV(tune_lgb, param_distributions=params_lgb, n_iter=40, scoring='roc_auc', n_jobs=4, cv=skf.split(X_train,y_train), verbose=1, random_state = 2137 )\nrand_lgb.fit(X_train, y_train)\nrand_lgb_pred = rand_lgb.predict_proba(X_test)\nprint(roc_auc_score(y_test, rand_lgb_pred[:, 1]))\nprint(confusion_matrix(y_test, np.round(rand_lgb_pred[:, 1])))","metadata":{"execution":{"iopub.status.busy":"2024-02-20T08:48:44.712182Z","iopub.execute_input":"2024-02-20T08:48:44.713102Z","iopub.status.idle":"2024-02-20T08:52:39.735678Z","shell.execute_reply.started":"2024-02-20T08:48:44.713051Z","shell.execute_reply":"2024-02-20T08:52:39.734377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tune_cat = cb.CatBoostClassifier()\nrand_cat = RandomizedSearchCV(tune_cat, param_distributions=params_cat, n_iter=40, scoring='roc_auc', n_jobs=4, cv=skf.split(X_train,y_train), verbose=1, random_state = 2137 )\nrand_cat.fit(X_train, y_train)\nrand_cat_pred = rand_cat.predict_proba(X_test)\nprint(roc_auc_score(y_test, rand_cat_pred[:, 1]))\nprint(confusion_matrix(y_test, np.round(rand_cat_pred[:, 1])))","metadata":{"execution":{"iopub.status.busy":"2024-02-20T09:33:24.808349Z","iopub.execute_input":"2024-02-20T09:33:24.808800Z","iopub.status.idle":"2024-02-20T09:38:59.454224Z","shell.execute_reply.started":"2024-02-20T09:33:24.808765Z","shell.execute_reply":"2024-02-20T09:38:59.453289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tune_ada = AdaBoostClassifier()\nrand_ada = RandomizedSearchCV(tune_ada, param_distributions=params_ada, n_iter=40, scoring='roc_auc', n_jobs=4, cv=skf.split(X_train,y_train), verbose=1, random_state = 2137 )\nrand_ada.fit(X_train, y_train)\nrand_ada_pred = rand_cat.predict_proba(X_test)\nprint(roc_auc_score(y_test, rand_ada_pred[:, 1]))\nprint(confusion_matrix(y_test, np.round(rand_ada_pred[:, 1])))","metadata":{"execution":{"iopub.status.busy":"2024-02-20T09:42:29.808394Z","iopub.execute_input":"2024-02-20T09:42:29.808977Z","iopub.status.idle":"2024-02-20T10:12:24.183850Z","shell.execute_reply.started":"2024-02-20T09:42:29.808939Z","shell.execute_reply":"2024-02-20T10:12:24.182407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# I use best params to create classifiers for my Ensemble","metadata":{}},{"cell_type":"code","source":"clf_xgb = xgb.XGBClassifier(**rand_xgb.best_params_,enable_categorical =  True, objective = 'binary:logistic')\nclf_lgb = lgb.LGBMClassifier(**rand_lgb.best_params_)\nclf_cat = cb.CatBoostClassifier(**rand_cat.best_params_)\nclf_ada = AdaBoostClassifier(**rand_ada.best_params_)\nclf_lr = LogisticRegression(class_weight = 'balanced', random_state = 2137)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T10:12:24.186282Z","iopub.execute_input":"2024-02-20T10:12:24.186745Z","iopub.status.idle":"2024-02-20T10:12:24.194692Z","shell.execute_reply.started":"2024-02-20T10:12:24.186714Z","shell.execute_reply":"2024-02-20T10:12:24.193570Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# And if you're interested in trying Voting Ensemble here you can find the code for it.","metadata":{}},{"cell_type":"code","source":"#clf_voting = VotingClassifier(\n#    estimators=[\n#        ('xgb', clf_xgb),\n#        ('lgb', clf_lgb),\n#        ('lr', clf_lr),\n#        ('cat', clf_cat),\n#        ('ada', clf_ada)],\n#    voting = 'soft',\n#    verbose=False\n#   \n#)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T10:12:24.196025Z","iopub.execute_input":"2024-02-20T10:12:24.196873Z","iopub.status.idle":"2024-02-20T10:12:24.217419Z","shell.execute_reply.started":"2024-02-20T10:12:24.196840Z","shell.execute_reply":"2024-02-20T10:12:24.215957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#clf_voting.fit(X_train, y_train)\n#y_pred = clf_voting.predict_proba(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T10:12:24.220372Z","iopub.execute_input":"2024-02-20T10:12:24.220738Z","iopub.status.idle":"2024-02-20T10:12:24.229051Z","shell.execute_reply.started":"2024-02-20T10:12:24.220708Z","shell.execute_reply":"2024-02-20T10:12:24.227967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(roc_auc_score(y_test, y_pred[:, 1]))","metadata":{"execution":{"iopub.status.busy":"2024-02-20T10:12:24.232940Z","iopub.execute_input":"2024-02-20T10:12:24.233341Z","iopub.status.idle":"2024-02-20T10:12:24.242787Z","shell.execute_reply.started":"2024-02-20T10:12:24.233311Z","shell.execute_reply":"2024-02-20T10:12:24.241537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test_df.columns","metadata":{"execution":{"iopub.status.busy":"2024-02-20T10:12:24.246908Z","iopub.execute_input":"2024-02-20T10:12:24.247299Z","iopub.status.idle":"2024-02-20T10:12:24.257590Z","shell.execute_reply.started":"2024-02-20T10:12:24.247270Z","shell.execute_reply":"2024-02-20T10:12:24.256402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sub_proba = clf_voting.predict_proba(test_df)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-20T10:12:24.259165Z","iopub.execute_input":"2024-02-20T10:12:24.259656Z","iopub.status.idle":"2024-02-20T10:12:24.272209Z","shell.execute_reply.started":"2024-02-20T10:12:24.259611Z","shell.execute_reply":"2024-02-20T10:12:24.271133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sub = test[['patient_id']]\n#sub['DiagPeriodL90D'] = sub_proba[:, 1]\n\n#sub.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-20T10:12:24.273223Z","iopub.execute_input":"2024-02-20T10:12:24.273546Z","iopub.status.idle":"2024-02-20T10:12:24.284115Z","shell.execute_reply.started":"2024-02-20T10:12:24.273519Z","shell.execute_reply":"2024-02-20T10:12:24.283047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sub.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T10:12:24.285241Z","iopub.execute_input":"2024-02-20T10:12:24.285623Z","iopub.status.idle":"2024-02-20T10:12:24.295280Z","shell.execute_reply.started":"2024-02-20T10:12:24.285594Z","shell.execute_reply":"2024-02-20T10:12:24.294058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifiers=[('xgb', clf_xgb),\n        ('lgb', clf_lgb),\n        ('lr', clf_lr),\n        ('cat', clf_cat),\n        ('ada', clf_ada)]","metadata":{"execution":{"iopub.status.busy":"2024-02-20T10:12:24.298950Z","iopub.execute_input":"2024-02-20T10:12:24.299398Z","iopub.status.idle":"2024-02-20T10:12:24.306036Z","shell.execute_reply.started":"2024-02-20T10:12:24.299364Z","shell.execute_reply":"2024-02-20T10:12:24.304848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf_meta = xgb.XGBClassifier(**rand_xgb.best_params_, enable_categorical =  True, objective = 'binary:logistic', random_state=2137 )","metadata":{"execution":{"iopub.status.busy":"2024-02-20T10:12:24.307667Z","iopub.execute_input":"2024-02-20T10:12:24.308044Z","iopub.status.idle":"2024-02-20T10:12:24.318227Z","shell.execute_reply.started":"2024-02-20T10:12:24.307981Z","shell.execute_reply":"2024-02-20T10:12:24.317103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# I tried both passthrough=False and passthrough=True and the latter one seems to work a bit better, but yeah it takes some time.","metadata":{}},{"cell_type":"code","source":"clf_stack= StackingClassifier(\n    estimators = classifiers,\n    final_estimator = clf_meta,\n    cv =3, \n    stack_method = 'predict_proba',\n    passthrough = True, \n    verbose = 3) ","metadata":{"execution":{"iopub.status.busy":"2024-02-20T10:12:24.319917Z","iopub.execute_input":"2024-02-20T10:12:24.320374Z","iopub.status.idle":"2024-02-20T10:12:24.331271Z","shell.execute_reply.started":"2024-02-20T10:12:24.320338Z","shell.execute_reply":"2024-02-20T10:12:24.330073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf_stack.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T10:12:24.332946Z","iopub.execute_input":"2024-02-20T10:12:24.333534Z","iopub.status.idle":"2024-02-20T10:28:08.426655Z","shell.execute_reply.started":"2024-02-20T10:12:24.333489Z","shell.execute_reply":"2024-02-20T10:28:08.425427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The scores on the X_test set don't differ that much from the scores of single classifiers.","metadata":{}},{"cell_type":"code","source":"stack_pred = clf_stack.predict_proba(X_test)\nprint(roc_auc_score(y_test, stack_pred[:, 1]))","metadata":{"execution":{"iopub.status.busy":"2024-02-20T10:28:08.428551Z","iopub.execute_input":"2024-02-20T10:28:08.432286Z","iopub.status.idle":"2024-02-20T10:28:15.830050Z","shell.execute_reply.started":"2024-02-20T10:28:08.432239Z","shell.execute_reply":"2024-02-20T10:28:15.828803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(confusion_matrix(y_test, np.round(stack_pred[:, 1])))","metadata":{"execution":{"iopub.status.busy":"2024-02-20T10:28:15.831403Z","iopub.execute_input":"2024-02-20T10:28:15.831762Z","iopub.status.idle":"2024-02-20T10:28:15.841094Z","shell.execute_reply.started":"2024-02-20T10:28:15.831732Z","shell.execute_reply":"2024-02-20T10:28:15.839832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.columns","metadata":{"execution":{"iopub.status.busy":"2024-02-20T08:53:00.968436Z","iopub.status.idle":"2024-02-20T08:53:00.968888Z","shell.execute_reply.started":"2024-02-20T08:53:00.968674Z","shell.execute_reply":"2024-02-20T08:53:00.968692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stack_proba = clf_stack.predict_proba(test_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-20T10:37:42.133513Z","iopub.execute_input":"2024-02-20T10:37:42.134025Z","iopub.status.idle":"2024-02-20T10:37:56.586415Z","shell.execute_reply.started":"2024-02-20T10:37:42.133978Z","shell.execute_reply":"2024-02-20T10:37:56.585305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_stack = test[['patient_id']]\nsub_stack['DiagPeriodL90D'] = stack_proba[:, 1]\nsub_stack.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-20T10:37:56.752283Z","iopub.execute_input":"2024-02-20T10:37:56.752686Z","iopub.status.idle":"2024-02-20T10:37:56.769393Z","shell.execute_reply.started":"2024-02-20T10:37:56.752655Z","shell.execute_reply":"2024-02-20T10:37:56.768248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_stack.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T10:37:56.882231Z","iopub.execute_input":"2024-02-20T10:37:56.882698Z","iopub.status.idle":"2024-02-20T10:37:56.908649Z","shell.execute_reply.started":"2024-02-20T10:37:56.882668Z","shell.execute_reply":"2024-02-20T10:37:56.907466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# As we can see also in confusion matrix there is still a group of missclassified patients. It's usually around 400. In my next notebook I'll try to perform residual analysis, maybe it will help to get that number down.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}